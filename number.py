# -*- coding: utf-8 -*-
"""手寫數字辨識.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vD5vmKL8MVVm8p0gqKbVRx2klLLSlaKi
"""

import tensorflow as tf
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

import matplotlib.pyplot as plt
fig = plt.figure
plt.imshow(x_train[0], cmap='gray')
plt.show()

y_train[0]

model = tf.keras.models.Sequential([
tf.keras.layers.Flatten(input_shape=(28, 28)),        
tf.keras.layers.Dense(12.8, activation='relu'),
tf.keras.layers.Dropout(0.2),
tf.keras.layers.Dense(10)      
])

model.summary()

model.compile(
  optimizer='adam',
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy']
)

epoch_num = 10
history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epoch_num)

epochs = range(1, epoch_num+1)
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.plot(epochs, loss, 'ko', label='training loss')
plt.plot(epochs, val_loss, 'ro', label='validation loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend()
plt.show()

epochs = range(1, epoch_num+1)
loss = history.history['accuracy']
val_loss = history.history['val_accuracy']

plt.plot(epochs, loss, 'ko', label='training loss')
plt.plot(epochs, val_loss, 'ro', label='validation loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend()
plt.show()

print(model.predict(x_test[0:3]))
plt.imshow(x_test[2],cmap='gray')
plt.show()

y_test[:3]

probability_model = tf.keras.Sequential([
  model,
  tf.keras.layers.Softmax()
])
probability_model(x_test[:3])
